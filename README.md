# An√°lise e Previs√£o de Churn - Desafio Telecom X

Este reposit√≥rio cont√©m a solu√ß√£o completa para o desafio de Data Science da Telecom X, focado em entender e prever a evas√£o de clientes (churn). O projeto est√° dividido em duas partes principais:

1.  **An√°lise Explorat√≥ria de Dados (EDA):** Investiga√ß√£o dos dados para identificar os principais fatores e perfis de clientes associados ao churn.
2.  **Modelagem Preditiva:** Constru√ß√£o, treinamento e avalia√ß√£o de modelos de Machine Learning para prever quais clientes t√™m maior probabilidade de cancelar o servi√ßo.

## üìÇ Estrutura do Reposit√≥rio
‚îú‚îÄ‚îÄ challenge_telecomx_parte1.ipynb # Notebook com a An√°lise Explorat√≥ria de Dados (EDA)

‚îú‚îÄ‚îÄ challenge_telecomx_parte2.ipynb # Notebook com a Modelagem Preditiva (Machine Learning)

‚îú‚îÄ‚îÄ dados_tratados.csv # Arquivo CSV gerado na Parte 1 e utilizado na Parte 2

‚îî‚îÄ‚îÄ README.md # Este arquivo

## üéØ Objetivo do Projeto

O objetivo central deste desafio √© utilizar dados de clientes da Telecom X para construir um pipeline de Data Science ponta a ponta, desde a coleta e limpeza de dados at√© a cria√ß√£o de um modelo preditivo acion√°vel. O resultado final visa fornecer insights e uma ferramenta para a empresa desenvolver estrat√©gias de reten√ß√£o mais eficazes, reduzindo a perda de receita associada ao churn.

---

## üìà Parte 1: An√°lise Explorat√≥ria de Dados (EDA)

O notebook `challenge_telecomx_parte1.ipynb` cobre todo o processo de ETL (Extra√ß√£o, Transforma√ß√£o e Carga) e an√°lise inicial.

### Principais Etapas:

1.  **Extra√ß√£o de Dados:** Os dados foram coletados diretamente de uma API em formato JSON e carregados em um DataFrame do Pandas.
2.  **Limpeza e Tratamento:**
    *   Corre√ß√£o de tipos de dados (ex: `TotalGasto` de texto para num√©rico).
    *   Tratamento de valores ausentes e inconsistentes, utilizando a mediana para imputa√ß√£o.
    *   Remo√ß√£o de registros que n√£o agregavam valor √† an√°lise de churn.
3.  **Engenharia de Features:**
    *   Cria√ß√£o de novas colunas como `Faturamento_Diario` e `Quantidade_Servicos` para aprofundar a an√°lise.
4.  **Padroniza√ß√£o:**
    *   Convers√£o de colunas bin√°rias (Sim/N√£o) para formato num√©rico (1/0).
    *   Renomea√ß√£o das colunas para facilitar a interpreta√ß√£o.

### Principais Descobertas da EDA:

A an√°lise revelou uma taxa de churn de **26,5%** e identificou um perfil claro de cliente com alta propens√£o a cancelar:

-   **Tipo de Contrato:** Clientes com contrato **M√™s a M√™s** s√£o os que mais cancelam.
-   **Tempo de Contrato (Tenure):** A maioria dos cancelamentos ocorre nos **primeiros meses**.
-   **Faturamento Mensal:** Faturas **mais altas** est√£o correlacionadas com maior churn.
-   **Servi√ßos Adicionais:** A aus√™ncia de servi√ßos de valor agregado, como **Suporte T√©cnico** e **Seguran√ßa Online**, √© um forte indicador de risco.

O DataFrame tratado e limpo foi salvo como `dados_tratados.csv` para ser utilizado na pr√≥xima fase.

---

## ü§ñ Parte 2: Modelagem Preditiva de Machine Learning

O notebook `challenge_telecomx_parte2.ipynb` foca na constru√ß√£o de modelos preditivos para identificar clientes com risco de churn.

### Principais Etapas:

1.  **Prepara√ß√£o para Modelagem:**
    *   Carregamento do arquivo `dados_tratados.csv`.
    *   Separa√ß√£o dos dados em vari√°veis preditoras (X) e vari√°vel alvo (y).
    *   Divis√£o em conjuntos de **treino (70%)** e **teste (30%)** de forma estratificada.
2.  **Pr√©-processamento com Pipeline:**
    *   Cria√ß√£o de um `ColumnTransformer` para aplicar `StandardScaler` em vari√°veis num√©ricas e `OneHotEncoder` em vari√°veis categ√≥ricas.
3.  **Constru√ß√£o e Treinamento dos Modelos:**
    *   **Modelo 1: Regress√£o Log√≠stica** - Um modelo linear robusto e interpret√°vel.
    *   **Modelo 2: Random Forest** - Um modelo de conjunto poderoso, com balanceamento de classes.
4.  **Avalia√ß√£o e Compara√ß√£o:**
    *   Os modelos foram avaliados usando **Acur√°cia**, **Relat√≥rio de Classifica√ß√£o** (Precis√£o, Recall, F1-Score) e a **Curva ROC/AUC**.

### Resultados Finais:

O modelo de **Regress√£o Log√≠stica foi o escolhido** por apresentar um desempenho superior e mais equilibrado, com um **AUC de 0.835** e um **Recall de 55%** para a classe "Churn", indicando uma excelente capacidade de identificar corretamente os clientes que ir√£o cancelar.

### Import√¢ncia das Vari√°veis (Feature Importance):

Os fatores que mais influenciam a previs√£o do modelo s√£o, em ordem de import√¢ncia:
1.  `Meses_de_Contrato`
2.  `Total_Gasto`
3.  `Faturamento_Mensal`
4.  `Tipo_Contrato_Month-to-month`
5.  `Forma_de_Pagamento_Electronic check`

---

## üöÄ Como Executar o Projeto no Google Colab

Para executar este projeto no Google Colab, n√£o √© necess√°rio instalar nenhuma depend√™ncia. Siga os passos abaixo:

1.  **Acesse o Google Colab:**
    *   V√° para [colab.research.google.com](https://colab.research.google.com).

2.  **Abra os notebooks a partir do GitHub:**
    *   No Colab, v√° em `Arquivo > Abrir notebook`.
    *   Selecione a aba **GitHub**.
    *   Cole a URL deste reposit√≥rio e pressione Enter.
    *   Abra o notebook `challenge_telecomx_parte1.ipynb`.

3.  **Execute a Parte 1:**
    *   No notebook `challenge_telecomx_parte1.ipynb`, v√° em `Ambiente de execu√ß√£o > Executar tudo`.
    *   Ao final da execu√ß√£o, o arquivo `dados_tratados.csv` ser√° gerado e salvo no ambiente tempor√°rio do Colab. Voc√™ poder√° v√™-lo no painel de arquivos √† esquerda.

4.  **Execute a Parte 2:**
    *   Repita o passo 2 para abrir o notebook `challenge_telecomx_parte2.ipynb`.
    *   Como o arquivo `dados_tratados.csv` j√° est√° no ambiente do Colab (gerado pela Parte 1), voc√™ pode simplesmente ir em `Ambiente de execu√ß√£o > Executar tudo` para treinar e avaliar os modelos.

> **Importante:** O ambiente do Google Colab √© tempor√°rio. Se sua sess√£o for desconectada, os arquivos gerados (como `dados_tratados.csv`) ser√£o perdidos. Por isso, √© essencial executar a Parte 1 antes da Parte 2 na mesma sess√£o.

## üõ†Ô∏è Ferramentas Utilizadas

*   **Linguagem:** Python 3
*   **Bibliotecas Principais:** Pandas, NumPy, Matplotlib, Seaborn, Scikit-learn, Requests
*   **Ambiente:** Jupyter Notebook / Google Colab
